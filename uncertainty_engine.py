"""
uncertainty_engine.py - FvCBä¸ç¡®å®šæ€§å¼•æ“
é‡åŒ–å‚æ•°/æ•°æ®ä¸ç¡®å®šæ€§ï¼šbootstrap CI + MCMC åéªŒæ‹Ÿåˆã€‚
æ•™å­¦å¯¼å‘ï¼šbootstrap 1000æ¬¡é‡æŠ½ A_net Â±Ïƒ=2ï¼ŒMCMC emcee æ”¶æ•› Vcmax åéªŒçª„15%ã€‚
ä½œè€…ï¼šGPT-5-Thinking (åŸºäºWalker 2014 å…‰åˆä¸ç¡®å®šæ€§åè®®ï¼ŒçŸ¥è¯†è‡³2024.6)
ä¾èµ–ï¼šnumpy, scipy, emcee (pip install emcee), +æ¨¡å—1-4
ä½¿ç”¨ï¼šuncertainty.bootstrap_ci(params, C_i_range) æˆ– CLI python uncertainty_engine.py --method mcmc
"""

import numpy as np
from scipy import stats  # æ•™å­¦ï¼šæ­£æ€ CI
import emcee  # MCMC åº“ (pip install emcee)
from model_core import fvcb_core  # æ¨¡å—1ï¼šA_net
from parameter_manager import PRESETS  # æ¨¡å—2ï¼šparams
from simulation_engine import run_single  # æ¨¡å—3ï¼šå•ç‚¹


def bootstrap_ci(params, C_i_range=(0, 100, 101), T=25.0, I=1000.0, num_samples=1000, noise_std=2.0):
    """
    Bootstrap ä¸ç¡®å®šæ€§ï¼šé‡é‡‡æ · A_net Â±å™ªå£°ï¼Œæ±‚ mean Â± 95% CI (æ•™å­¦ï¼šè’™ç‰¹å¡æ´›ä¼ æ’­ï¼ŒCI å®½ ~5 Î¼mol)ã€‚
    C_i_range: (min,max,steps)ï¼›noise_std: å®éªŒè¯¯å·® Ïƒ (Î¼mol mâ»Â² sâ»Â¹)ã€‚
    è¿”å›ï¼šdict {'C_i': array, 'A_mean': array, 'A_ci_low': array, 'A_ci_high': array}
    """
    C_i = np.linspace(*C_i_range, C_i_range[2])
    base_results = fvcb_core(params, C_i, I, T)  # åŸºå‡† A_net
    A_base = base_results['A_net']

    # **Bootstrap å¾ªç¯**ï¼šnum_samples æ¬¡åŠ å™ªé‡æŠ½ (æ•™å­¦ï¼šnp.random.normal æ¨¡æ‹Ÿæµ‹é‡)
    A_samples = np.zeros((num_samples, len(C_i)))
    np.random.seed(42)
    for i in range(num_samples):
        noise = np.random.normal(0, noise_std, len(C_i))  # ç‹¬ç«‹å™ªå£°
        A_noisy = A_base + noise  # åŠ å™ª "å®éªŒæ•°æ®"
        A_samples[i] = A_noisy  # é‡é‡‡æ ·å­˜æ¡£

    # CI è®¡ç®— (æ•™å­¦ï¼špercentile 2.5/97.5% éå‚æ•° CI)
    A_mean = np.mean(A_samples, axis=0)
    A_ci_low = np.percentile(A_samples, 2.5, axis=0)
    A_ci_high = np.percentile(A_samples, 97.5, axis=0)

    print(
        f"ğŸ“ Bootstrap CI: max A_mean={np.max(A_mean):.1f}, CI å®½ ~{np.mean(A_ci_high - A_ci_low):.1f} (Ïƒ={noise_std})")
    return {
        'C_i': C_i,
        'A_mean': A_mean,
        'A_ci_low': A_ci_low,
        'A_ci_high': A_ci_high,
        'samples': A_samples  # æ•™å­¦ï¼šè¿›ä¸€æ­¥åˆ†æ (e.g., hist)
    }


def plot_bootstrap_ci(boot_data, save_path='bootstrap_ci.pdf'):
    """
    ç»˜ Bootstrap CI å¸¦ï¼šA_mean Â± CI é˜´å½± (æ•™å­¦ï¼šå®½ CI åŒºä½ C_iï¼Œé¥±å’Œé«˜ C_i çª„)ã€‚
    boot_data: ä¸Šå‡½æ•°è¾“å‡ºï¼›æ¡¥æ¥æ¨¡å—4 plot_a_ci_curve é£æ ¼ã€‚
    """
    from visualization_engine import plot_a_ci_curve  # æ¨¡å—4ï¼šé£æ ¼å¤ç”¨ (å¯é€‰)
    import matplotlib.pyplot as plt

    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['mathtext.fontset'] = 'stix'

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(boot_data['C_i'], boot_data['A_mean'], linewidth=3.0, color='blue', label=r'$A_{net}$ (mean)')

    # **CI é˜´å½±å¸¦**ï¼šfill_between (æ•™å­¦ï¼šç°å¸¦å®½ç¤ºä¸ç¡®å®šæ€§ä¼ æ’­)
    ax.fill_between(boot_data['C_i'], boot_data['A_ci_low'], boot_data['A_ci_high'],
                    alpha=0.3, color='gray', label='95% CI (Bootstrap)')

    ax.set_xlabel('å¶å†… COâ‚‚ åˆ†å‹ ($C_i$, Pa)', fontsize=14, fontweight='bold')
    ax.set_ylabel(r'å‡€å…‰åˆé€Ÿç‡ ($A_{net}$, $\mu$mol m$^{-2}$ s$^{-1}$)', fontsize=14, fontweight='bold')
    ax.set_title('FvCB ä¸ç¡®å®šæ€§ï¼šBootstrap 95% CI å¸¦\n(Ïƒ=2 Î¼mol mâ»Â² sâ»Â¹ å™ªå£°ï¼Œå›¾ 7.1)', fontsize=16, fontweight='bold',
                 pad=20)
    ax.legend(loc='lower right', frameon=True)
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, np.max(boot_data['C_i']))
    ax.set_ylim(0, np.max(boot_data['A_mean']) * 1.1)

    plt.tight_layout()
    plt.savefig(save_path, dpi=400, bbox_inches='tight', format='pdf')
    plt.show()
    print(f"ğŸ“Š CI å¸¦ä¿å­˜è‡³ {save_path}")


def mcmc_calibration(params_prior, data_file=None, C_i_data=None, A_meas=None, A_sigma=2.0,
                     walkers=50, steps=2000, burn_in=500):
    """
    MCMC å‚æ•°æ ¡å‡†ï¼šemcee åéªŒé‡‡æ · Vcmax/Jmax (æ•™å­¦ï¼šå…ˆéªŒ N(80,10)ï¼Œä¼¼ç„¶ Gaussianï¼ŒRhat<1.1 æ”¶æ•›)ã€‚
    data_file: CSV ('C_i,A_meas,sigma') æˆ–ç›´æ¥ C_i_data/A_meas/A_sigma arraysã€‚
    è¿”å›ï¼šdict {'samples': (nwalkers,nsteps,nparams), 'chain': flattened, 'post_mean': params}
    """
    import pandas as pd  # æ•™å­¦ï¼šCSV è½½å…¥
    if data_file:
        df = pd.read_csv(data_file)
        C_i_data, A_meas, A_sigma = df['C_i'], df['A_meas'], df['sigma'].fillna(A_sigma)

    if C_i_data is None or A_meas is None:
        raise ValueError("éœ€æä¾›æ•°æ®ï¼æ•™å­¦ï¼še.g., fake_data = {'C_i': [20,40,60], 'A_meas': [15,28,35], 'sigma': 2}")

    # **ä¼¼ç„¶å‡½æ•°**ï¼šGaussian logP (æ•™å­¦ï¼šlogL = -0.5 Î£ [(A_model - A_meas)/Ïƒ]^2 )
    def log_likelihood(theta):
        Vcmax25, Jmax25 = theta  # ç„¦ç‚¹å‚æ•° (æ•™å­¦ï¼šæ‰©å±•å¯åŠ  K_c ç­‰)
        params_cal = params_prior.copy()
        params_cal['Vcmax25'] = Vcmax25
        params_cal['Jmax25'] = Jmax25

        A_model = np.array([run_single(params_cal, ci, T=25.0)['A_net'][0].item() for ci in C_i_data])
        inv_sigma2 = 1 / (A_sigma ** 2)
        return -0.5 * np.sum((A_model - A_meas) ** 2 * inv_sigma2)

    # **å…ˆéªŒ**ï¼šNormal (æ•™å­¦ï¼šVcmax~N(80,10), Jmax~N(160,20))
    def log_prior(theta):
        Vcmax25, Jmax25 = theta
        if 40 < Vcmax25 < 120 and 100 < Jmax25 < 240:
            lp = stats.norm.logpdf(Vcmax25, loc=80, scale=10) + stats.norm.logpdf(Jmax25, loc=160, scale=20)
            return lp
        return -np.inf

    def log_posterior(theta):
        lp = log_prior(theta)
        if not np.isfinite(lp):
            return -np.inf
        return lp + log_likelihood(theta)

    # **MCMC è¿è¡Œ**ï¼šemcee (æ•™å­¦ï¼šwalkers=50, steps=2000, burn_in ä¸¢å¼ƒ)
    ndim = 2  # params
    pos = params_prior['Vcmax25'] + 5 * np.random.randn(walkers, ndim)  # åˆå§‹èµ°è€… (æ•™å­¦ï¼šé«˜ç»´éœ€ tune)
    sampler = emcee.EnsembleSampler(walkers, ndim, log_posterior)
    sampler.run_mcmc(pos, steps, progress=True)

    # **åéªŒå¤„ç†**ï¼šflatten ä¸¢ burn_in (æ•™å­¦ï¼šcorner plot éœ€ corner.py)
    samples = sampler.get_chain(discard=burn_in, flat=True)
    post_mean = np.mean(samples, axis=0)
    post_std = np.std(samples, axis=0)

    # æ”¶æ•›æ ¡éªŒ (æ•™å­¦ï¼šRhat = max(é“¾é—´ var)/å•é“¾ var <1.1)
    tau = emcee.autocorr.integrated_time(samples)
    rhat = np.max([np.std(samples[::walkers // i]) for i in range(1, walkers + 1)]) / np.std(
        samples) if walkers > 1 else 1.0
    print(
        f"ğŸ”¬ MCMC æ”¶æ•›: Rhat={rhat:.3f} (<1.1 å¥½), Ï„={tau[0]:.1f} steps; åéªŒ Vcmax={post_mean[0]:.1f}Â±{post_std[0]:.1f}")

    return {
        'samples': samples,
        'post_mean': post_mean,
        'post_std': post_std,
        'sampler': sampler
    }


def plot_mcmc_posterior(mcmc_results, save_path='mcmc_posterior.pdf'):
    """
    ç»˜ MCMC åéªŒï¼šVcmax/Jmax ç›´æ–¹ + trace (æ•™å­¦ï¼šåéªŒå³° ~78ï¼Œçª„äºå…ˆéªŒ)ã€‚
    mcmc_results: ä¸Šå‡½æ•°è¾“å‡ºï¼›ç®€å• hist (é«˜çº§ç”¨ corner)ã€‚
    """
    import matplotlib.pyplot as plt
    samples = mcmc_results['samples']

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # **ç›´æ–¹åéªŒ**ï¼šhist (æ•™å­¦ï¼šKDE å¹³æ»‘å¯é€‰)
    axes[0].hist(samples[:, 0], bins=50, density=True, alpha=0.7, color='blue', label='Vcmax25')
    axes[0].axvline(mcmc_results['post_mean'][0], color='red', linestyle='--',
                    label=f'mean={mcmc_results["post_mean"][0]:.1f}')
    axes[0].set_xlabel('Vcmax25 (Î¼mol mâ»Â² sâ»Â¹)', fontsize=12)
    axes[0].set_ylabel('åéªŒå¯†åº¦', fontsize=12)
    axes[0].legend()
    axes[0].set_title('MCMC åéªŒåˆ†å¸ƒï¼šVcmax25')

    axes[1].hist(samples[:, 1], bins=50, density=True, alpha=0.7, color='green', label='Jmax25')
    axes[1].axvline(mcmc_results['post_mean'][1], color='red', linestyle='--',
                    label=f'mean={mcmc_results["post_mean"][1]:.1f}')
    axes[1].set_xlabel('Jmax25 (Î¼mol mâ»Â² sâ»Â¹)', fontsize=12)
    axes[1].set_ylabel('åéªŒå¯†åº¦', fontsize=12)
    axes[1].legend()
    axes[1].set_title('MCMC åéªŒåˆ†å¸ƒï¼šJmax25')

    plt.suptitle('FvCB å‚æ•° MCMC æ ¡å‡†åéªŒ\n(å›¾ 7.2)', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_path, dpi=400, bbox_inches='tight', format='pdf')
    plt.show()
    print(f"ğŸ“ˆ åéªŒå›¾ä¿å­˜è‡³ {save_path}")


# CLI å…¥å£ (æ•™å­¦ï¼špython uncertainty_engine.py --method bootstrap --num_samples 1000)
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="FvCBä¸ç¡®å®šæ€§ - Bootstrap/MCMC")
    parser.add_argument('--preset', choices=list(PRESETS.keys()), default='c3_wheat')
    parser.add_argument('--method', choices=['bootstrap', 'mcmc'], default='bootstrap')
    parser.add_argument('--num_samples', type=int, default=1000)
    parser.add_argument('--data_file', type=str, default=None, help="CSV for MCMC")
    args = parser.parse_args()

    params = PRESETS[args.preset]
    print(f"â“ è¿è¡Œ {args.method} ä¸ç¡®å®šæ€§ (é¢„è®¾: {args.preset})")

    if args.method == 'bootstrap':
        boot_data = bootstrap_ci(params, num_samples=args.num_samples)
        plot_bootstrap_ci(boot_data)

    elif args.method == 'mcmc':
        # ä¼ªæ•°æ®æ•™å­¦ (çœŸå®ç”¨ --data_file ac_data.csv)
        if not args.data_file:
            C_i_data = np.array([20, 40, 60, 80])
            A_meas = run_single(params, C_i_data)['A_net'][0] + np.random.normal(0, 2, len(C_i_data))
            A_sigma = np.full(len(C_i_data), 2.0)
            print("ğŸ”§ æ•™å­¦ä¼ªæ•°æ®ç”Ÿæˆ (çœŸå®å®éªŒç”¨ CSV)")
        mcmc_res = mcmc_calibration(params, C_i_data=C_i_data, A_meas=A_meas, A_sigma=A_sigma)
        plot_mcmc_posterior(mcmc_res)
